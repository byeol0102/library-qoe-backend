# backend/app.py

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import numpy as np
import pandas as pd
import joblib
import tensorflow as tf
import os
import datetime
from datetime import timedelta
import hashlib

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ---------------------------------------------------------
# 1. ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ
# ---------------------------------------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_DIR = os.path.join(BASE_DIR, "models")

scaler = joblib.load(os.path.join(MODEL_DIR, "scaler.pkl"))
# compile=False: í•™ìŠµ ì„¤ì • ë¬´ì‹œí•˜ê³  ê¹¡í†µ ëª¨ë¸ë§Œ ë¡œë“œ (ë²„ì „ í˜¸í™˜ì„± í•´ê²°)
gru_model = tf.keras.models.load_model(os.path.join(MODEL_DIR, "gru_qoe.h5"), compile=False)

csv_path = os.path.join(BASE_DIR, "db", "dataset_plus.csv")
try:
    df_all = pd.read_csv(csv_path, encoding='cp949')
except:
    df_all = pd.read_csv(csv_path, encoding='utf-8')

df_all.columns = [c.strip() for c in df_all.columns]

# ---------------------------------------------------------
# ğŸ”¥ [í•µì‹¬] ì‚¬ìš©ìê°€ ì œê³µí•œ "í•™ìŠµ ê³µì‹" ê·¸ëŒ€ë¡œ ì ìš©
# ---------------------------------------------------------
def log_norm_bad(series, max_val):
    # ê°’ì´ í´ìˆ˜ë¡ 1ì— ê°€ê¹ê²Œ (ë‚˜ì¨)
    return np.clip(np.log1p(series) / np.log1p(max_val), 0, 1)

def log_norm_good(series, max_val):
    # ê°’ì´ í´ìˆ˜ë¡ 0ì— ê°€ê¹ê²Œ (ì¢‹ìŒ -> ë‚˜ì¨ ì ìˆ˜ë‹ˆê¹Œ ë’¤ì§‘ìŒ)
    return 1 - np.clip(np.log1p(series) / np.log1p(max_val), 0, 1)

def clamp(x): return np.clip(x, 0, 1)

print("â³ í•™ìŠµ ê³µì‹ëŒ€ë¡œ QoE ì¬ê³„ì‚° ì¤‘...")

# 1. ìƒìˆ˜ ì •ì˜ (í•™ìŠµ ë•Œ ì“´ ê°’)
MAX_PING, MAX_JITTER, MAX_LOSS = 500.0, 100.0, 20.0
MAX_SPEED, MAX_CLIENTS = 500.0, 100.0

# 2. ì •ê·œí™” (Normalization)
# ì—†ëŠ” ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ì±„ì›Œì„œ ì—ëŸ¬ ë°©ì§€
if "ping_jitter_ms" not in df_all.columns: df_all["ping_jitter_ms"] = 0
if "RSSI" not in df_all.columns: df_all["RSSI"] = -60
if "client" not in df_all.columns: df_all["client"] = 0

df_all["norm_ping"]   = log_norm_bad(df_all["ping_ms"], MAX_PING)
df_all["norm_jitter"] = log_norm_bad(df_all["ping_jitter_ms"], MAX_JITTER)
df_all["norm_loss"]   = log_norm_bad(df_all["packet_loss_rate"], MAX_LOSS)
df_all["norm_speed"]  = log_norm_good(df_all["download_Mbps"], MAX_SPEED)
# RSSIëŠ” ë³´í†µ -30(ì¢‹ìŒ) ~ -90(ë‚˜ì¨). ì‹ì— ë”°ë¥´ë©´ -40 -> 0, -90 -> 1.0
df_all["norm_rssi"]   = clamp((df_all["RSSI"] + 40) / -50.0)
df_all["norm_clients"]= log_norm_bad(df_all["client"], MAX_CLIENTS)

# 3. ê°€ì¤‘ì¹˜ í•©ì‚° (Weighted Sum)
weights = {"norm_ping": 0.25, "norm_jitter": 0.15, "norm_loss": 0.20,
           "norm_speed": 0.25, "norm_rssi": 0.10, "norm_clients": 0.05}

bad_score = np.zeros(len(df_all))
for c in weights: 
    bad_score += df_all[c].values * weights[c]

# 4. EWM (ì§€ìˆ˜ ì´ë™ í‰ê· ) ì ìš© -> ì‹œê³„ì—´ íë¦„ ë°˜ì˜
# span=12ëŠ” ì•½ 12ê°œ ë°ì´í„°(ì•½ 1ì‹œê°„?)ì˜ íë¦„ì„ ë°˜ì˜í•œë‹¤ëŠ” ëœ»
df_all["QoE_index"] = pd.Series(bad_score).ewm(span=12, adjust=False).mean()
df_all["QoE_index"] = clamp(df_all["QoE_index"])

# 5. ëª¨ë¸ ì…ë ¥ìš© ì¶”ê°€ ë³€ìˆ˜ë“¤ (í•™ìŠµ ë•Œ ì“´ Featureë“¤)
df_all["log_download"] = np.log1p(df_all["download_Mbps"])
df_all["log_upload"] = np.log1p(df_all["upload_Mbps"])
df_all["ping_ms_diff"] = df_all.groupby("ap_code")["ping_ms"].diff().fillna(0)
df_all["download_Mbps_diff"] = df_all.groupby("ap_code")["download_Mbps"].diff().fillna(0)

# ì‹œê°„ ì»¬ëŸ¼ ì²˜ë¦¬
if 'datetime' in df_all.columns:
    df_all['dt_obj'] = pd.to_datetime(df_all['datetime'], errors='coerce')
    df_all['hour'] = df_all['dt_obj'].dt.hour
else:
    df_all['hour'] = 12

print("âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ! (User Formula Applied)")

FEATURES = [
    "ping_ms", "ping_jitter_ms", "packet_loss_rate",
    "log_download", "log_upload", "RSSI", "client",
    "norm_ping", "norm_speed", "norm_loss",
    "ping_ms_diff", "download_Mbps_diff"
]

def to_grade(qoe):
    # ğŸ”¥ [ì¤‘ìš”] ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ Good (ë¶ˆë§Œì¡± ì§€ìˆ˜ì´ë¯€ë¡œ)
    # 0.0 (ì™„ë²½) ~ 1.0 (ìµœì•…)
    if qoe <= 0.2: return "Good"       # 0.2 ì´í•˜ëŠ” ì´ˆë¡ìƒ‰ (ì¾Œì )
    elif qoe <= 0.4: return "Moderate" # 0.2~0.4ëŠ” ë…¸ë€ìƒ‰ (ë³´í†µ)
    else: return "Bad"                 # 0.4 ì´ˆê³¼ëŠ” ë¹¨ê°„ìƒ‰ (ë‚˜ì¨)

# ---------------------------------------------------------
# ğŸŒ [ì¶”ê°€] GPS ë¬¸ìì—´ íŒŒì‹± í—¬í¼ í•¨ìˆ˜
# ì˜ˆ: "(36.369872, 127.346647)" -> 36.369872, 127.346647
# ---------------------------------------------------------
def parse_gps(gps_str):
    try:
        # ê´„í˜¸ ì œê±°í•˜ê³  ì‰¼í‘œë¡œ ë‚˜ëˆ„ê¸°
        clean_str = str(gps_str).replace('(', '').replace(')', '')
        lat, lon = map(float, clean_str.split(','))
        return lat, lon
    except:
        return None, None

# backend/app.py ì˜ dashboard_summary í•¨ìˆ˜ êµì²´

@app.get("/api/dashboard")
def dashboard_summary(floor: str = "1F"): 
    # 1. í•´ë‹¹ ì¸µ ë°ì´í„° í•„í„°ë§
    floor_df = df_all[df_all['location2'].str.contains(floor, na=False)]
    
    if len(floor_df) == 0:
        return {"floor": floor, "aps": [], "alert_count": 0}

    unique_aps = floor_df.groupby("ap_code").last().reset_index()
    
    # ---------------------------------------------------------
    # ğŸ”¥ [ìˆ˜ë™ ì¢Œí‘œ ë§¤í•‘] (GPS ëŒ€ì‹  í™”ë©´ìƒ % ì¢Œí‘œ ì‚¬ìš©)
    # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì§€ë„ë¥¼ í´ë¦­í•´ì„œ ì–»ì€ ê°’ì„ ì—¬ê¸°ì— ì ìœ¼ë©´ ë¨
    # í˜•ì‹: "AP_ID": (ê°€ë¡œ%, ì„¸ë¡œ%)
    # ---------------------------------------------------------
    FIXED_POSITIONS = {
        # ì˜ˆì‹œ: ë‚´ê°€ ì„ì˜ë¡œ ì¡ì•„ë‘” ìœ„ì¹˜ (ë„ˆì˜ ë„ë©´ì— ë§ê²Œ ê³ ì³ì•¼ í•¨!)
        "CLIENT_AP_1F104H0013121": (27.3, 49.7),  
        "CLIENT_AP_1F104H0007121": (30.5, 37.7),  
        "CLIENT_AP_1F110H0024121": (76.9, 32.9),  
        "CLIENT_AP_B1F0138121": (69.4, 37.5),
        "CLIENT_AP_B2F0155121": (79.0, 26.0),
        "CLIENT_AP_B2F0146121": (34.2, 62.0),
        "CLIENT_AP_2F207H0055121": (61.8, 32.0),
    }

    ap_list = []
    
    for _, row in unique_aps.iterrows():
        ap_id = row['ap_code']
        qoe = row['QoE_index']
        
        # 1. ìš°ë¦¬ê°€ ì¢Œí‘œë¥¼ ì§€ì •í•´ë‘” APë©´ ê·¸ ìœ„ì¹˜ ì‚¬ìš©
        if ap_id in FIXED_POSITIONS:
            x, y = FIXED_POSITIONS[ap_id]
        
        # 2. ì§€ì • ì•ˆ ëœ APëŠ” ì¼ë‹¨ ì™¼ìª½ ìƒë‹¨ì— ëª¨ì•„ë‘ê¸° (ì°¾ê¸° ì‰½ê²Œ)
        else:
            x, y = 5, 5 # (5%, 5%) ìœ„ì¹˜
        
        ap_list.append({
            "id": ap_id, 
            "x": x, 
            "y": y, 
            "status": to_grade(qoe), 
            "qoe": round(qoe, 2)
        })

    return {
        "floor": floor,
        "aps": ap_list,
        "alert_count": sum(1 for ap in ap_list if ap["status"] != "Good")
    }

@app.get("/api/predict/{ap_id}")
def predict_ap(ap_id: str):
    now = datetime.datetime.now()
    future_time = now + timedelta(minutes=5)

    my_ap_df = df_all[df_all['ap_code'] == ap_id]
    
    if len(my_ap_df) < 10:
        return {"error": "ë°ì´í„° ë¶€ì¡±"}

    # ì‹œê°„ ë™ê¸°í™” (ì´ˆ ë‹¨ìœ„)
    cur_min = now.minute
    cur_sec = now.second
    total_sec = cur_min * 60 + cur_sec
    target_idx = total_sec % (len(my_ap_df) - 6)
    
    temp_df = my_ap_df.iloc[target_idx : target_idx + 6].copy()

    try:
        X = temp_df[FEATURES].values
        X_scaled = scaler.transform(X)
        X_seq = np.expand_dims(X_scaled, axis=0)

        # AI ì˜ˆì¸¡ (ëª¨ë¸ë„ ë‚®ì€ ì ìˆ˜ê°€ Goodìœ¼ë¡œ í•™ìŠµë˜ì—ˆì„ ê²ƒì„)
        pred_qoe = float(gru_model.predict(X_seq, verbose=0)[0, 0])
        curr_qoe = float(temp_df["QoE_index"].iloc[-1])

        time_str_now = now.strftime("%H:%M:%S")
        time_str_future = future_time.strftime("%H:%M")

        return {
            "ap_id": ap_id,
            "current_time_text": f"í˜„ì¬ ({time_str_now})",
            "future_time_text": f"5ë¶„ ë’¤ ì˜ˆì¸¡ ({time_str_future})",
            "current_qoe": round(curr_qoe, 2),
            "future_qoe": round(pred_qoe, 2),
            "current_grade": to_grade(curr_qoe),
            "future_grade": to_grade(pred_qoe),
            "metrics": temp_df.iloc[-1].to_dict()
        }

    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")
        return {"error": str(e)}

@app.get("/api/recommend")
def recommend_zone():
    # ì¸µë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í‰ê·  QoE ê³„ì‚°
    floor_groups = {}
    
    for floor_name in ["B2", "B1", "1F", "2F"]:
        floor_df = df_all[df_all['location2'].str.contains(floor_name, na=False)]
        if len(floor_df) > 0:
            # ê° ì¸µì˜ ìµœì‹  ë°ì´í„°ë§Œ ì‚¬ìš©
            unique_aps = floor_df.groupby("ap_code").last().reset_index()
            avg_qoe = unique_aps['QoE_index'].mean()
            floor_groups[floor_name] = {
                "name": f"{floor_name}ì¸µ",
                "qoe": avg_qoe,
                "grade": to_grade(avg_qoe),
                "ap_count": len(unique_aps)
            }
    
    # QoEê°€ ê°€ì¥ ë‚®ì€(ì¢‹ì€) ì¸µ ì°¾ê¸°
    if not floor_groups:
        return {
            "best_zone": "ë°ì´í„° ì—†ìŒ",
            "message": "ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "zones": []
        }
    
    best_floor = min(floor_groups.items(), key=lambda x: x[1]['qoe'])
    best_zone_name = best_floor[1]['name']
    
    # ë©”ì‹œì§€ ìƒì„±
    if best_floor[1]['grade'] == "Good":
        message = "AI ë¶„ì„ ê²°ê³¼ ê°€ì¥ ì¾Œì í•œ ë„¤íŠ¸ì›Œí¬ í™˜ê²½ì…ë‹ˆë‹¤."
    elif best_floor[1]['grade'] == "Moderate":
        message = "AI ë¶„ì„ ê²°ê³¼ ë³´í†µ ìˆ˜ì¤€ì˜ ë„¤íŠ¸ì›Œí¬ í™˜ê²½ì…ë‹ˆë‹¤."
    else:
        message = "AI ë¶„ì„ ê²°ê³¼ ë„¤íŠ¸ì›Œí¬ ìƒíƒœê°€ ì¢‹ì§€ ì•ŠìŠµë‹ˆë‹¤."
    
    # ëª¨ë“  ì¸µì„ QoE ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_zones = sorted(floor_groups.values(), key=lambda x: x['qoe'])
    
    return {
        "best_zone": best_zone_name,
        "message": message,
        "zones": [
            {
                "name": zone["name"],
                "grade": zone["grade"],
                "qoe": round(zone["qoe"], 2),
                "ap_count": zone["ap_count"]
            }
            for zone in sorted_zones
        ]
    }